#+TITLE: Redefine Success, Redefine Relevance.
#+AUTHOR: Paul Feitzinger
#+OPTIONS: H:1 toc:nil
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: default
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_HEADER:

* So much irrelevance
  #+CAPTION:
  [[./images/english-triggers.png]]
  - Read the left-most bar of this graph like this: "Out of the 360 colag
    english sentences, there were 225 global triggers for SP=0, and 100ish
    sentences that were ambiguously relevant to its value-setting. The rest were
    irrelevant."
  - Notably, "There are no languages in Colag English relevant to Null Subject
    or Wh-movement."
* But look, the NDL can see NS and WHM!
  [[./images/ndl-triggers.png]]
* Our definition of irrelevant
  :PROPERTIES:
  :BEAMER_opt: shrink=12
  :END:

  - Our algorithm considers a sentence $s$ irrelevant to a parameter $p$ when it
    fails to find a single example of where toggling $p$ in any of the grammars
    that license $s$, causes $s$ to no longer be licensed.

  \begin{align*}
  G_{sent} &= \text{the set of grammars that license sentence $sent$} \\
  g_p &= \text{The value of param $p$ in grammar $g$} \\
  pair_p^g &= \text{The minimal pair of $g$ on param $p$ (aka $g$ with $p$ toggled)} \\
    Trig(sent) &= \begin{bmatrix} Trig(sent, p) : p \in 1..13 \end{bmatrix} \\
    Trig(sent, p) &= \left\{\begin{array}{lr}
        0                        & \iff \{g_p : g \in G_{sent} \} = \{0\} \\
        1                        & \iff \{g_p : g \in G_{sent} \} = \{1\}\\
        Irrel?(G_{sent}, p) & \iff \{g_p : g \in G_{sent} \} = \{0, 1\} \\
        \end{array}\right\} \\
  Irrel?(G_{sent}, p) &= \left\{\begin{array}{lr}
        Ambig                        & \iff \exists g \in G_{sent} :
                                       (pair_p^g \notin G_{sent}) \cap (pair_p^g \in G) \\
        Irrel                        & \iff  otherwise \\
        \end{array}\right\} \\
  \end{align*}
* Weakly equivalent, hamming distance of 1
  - But this means any language $L$ with a weakly equivalent language $L'$,
    where then hamming distance between $L$ and $L'$ = 1, will cause lots of
    irrelevance in sentences. [[./images/weak-equiv-ham-dist.png]]
  - which describes 60% of the languages in Colag.
* Learning $g$ exactly
  [[./images/all-triggers.png]]
  - What we're really saying is, if we define successful learning to mean
    "seeing a sample of $L(g)$ and arriving at $g$ exactly", then these are how
    many strong, ambiguous, and irrelevant triggers exist for arriving at that
    hypothesis.
* Learning $g$ exactly
  - But that requires our learner to be able to differentiate between weakly
    equivalent languages [fn::languages where $L(g) = L(g')$ - the set of
    sentences generated by $g$ and $g'$ are exactly the same (though not
    necessarily the parses of those sentences).]
  - We don't claim our learners can actually do this (besides the TLA?), so
    perhaps we should relax our definition of successful learning when computing
    the per-parameter triggers.
* Learning $g$ or a Weak Equivalent
  :PROPERTIES:
  :BEAMER_opt: shrink=12
  :END:
  - This algorithm finds $s$ irrelevant to $p$ when it fails to find a single
    example of when toggling $p$ in any of the /non-g-equivalent-grammars/ that
    license $s$, causes $s$ to no longer be licensed.
  \begin{align*}
  G_{sent} &= \text{the set of grammars that license sentence $sent$} \\
  W_g &= \text{the set of grammars weakly equivalent to $g$} \\
  \bar{W}_{sent}^g &= \text{the grammars that license $sent$, excluding $W_g$} \\
  g_p &= \text{The value of param $p$ in grammar $g$} \\
  pair_p^g &= \text{The minimal pair of $g$ on param $p$ (aka $g$ with $p$ toggled)} \\
    Trig(sent) &= \begin{bmatrix} Trig(sent, p) : p \in 1..13 \end{bmatrix} \\
    Trig(sent, p) &= \left\{\begin{array}{lr}
        0                        & \iff \{g_p : g \in G_{sent} \} = \{0\} \\
        1                        & \iff \{g_p : g \in G_{sent} \} = \{1\}\\
        Irrel?(G_{sent}, p) & \iff \{g_p : g \in G_{sent} \} = \{0, 1\} \\
        \end{array}\right\} \\
  Irrel?(G_{sent}, p) &= \left\{\begin{array}{lr}
        Ambig                        & \iff \exists g \in G_{sent} :
                                       (pair_p^g \notin \bar{W}_{sent}^g) \cap (pair_p^g \in G) \\
        Irrel                        & \iff  otherwise \\
        \end{array}\right\} \\
  \end{align*}
* Learning $g$ or a Weak Equivalent
  [[./images/all-triggers-weak-equiv.png]]

  - If we settle for learning either $G$ or a weakly equivalent language, then
    the following number of sentences go from irrelevant to ambiguously
    relevant.
    |  opt | ItoC | ah     | QInv |
    |------+------+--------+------|
    | 5047 |   71 | 12,591 | 5732 |
* Learning $g$ or a Weak Equivalent
  - Here's how Colag English looks under that definition:

  [[./images/english-triggers-weak-equiv.png]]

* Superset relation, hamming distance of 1
  - It's also the case that any $g$ with a hamming-distance-1 superset language
    will cause irrelevance to be assigned to many sentences:

    [[./images/superset-ham-dist.png]]
* Learning $g$ or any Superset
  :PROPERTIES:
  :BEAMER_opt: shrink=12
  :END:
  - We could lower the bar even further and say that we've succeeded if we learn
    $g$ or any of its subset languages.
  - This algorithm finds $s$ irrelevant to $p$ when it fails to find a single
    example of when toggling $p$ in any of the /non-g-subset-grammars/ that
    license $s$, causes $s$ to no longer be licensed.

  \begin{align*}
  G_{sent} &= \text{the set of grammars that license sentence $sent$} \\
  S_g &= \text{the set of grammars in superset relation to $g$} \\
  \bar{S}_{sent}^g &= \text{the grammars that license $sent$, excluding $S_g$} \\
  g_p &= \text{The value of param $p$ in grammar $g$} \\
  pair_p^g &= \text{The minimal pair of $g$ on param $p$ (aka $g$ with $p$ toggled)} \\
    Trig(sent) &= \begin{bmatrix} Trig(sent, p) : p \in 1..13 \end{bmatrix} \\
    Trig(sent, p) &= \left\{\begin{array}{lr}
        0                        & \iff \{g_p : g \in G_{sent} \} = \{0\} \\
        1                        & \iff \{g_p : g \in G_{sent} \} = \{1\}\\
        Irrel?(G_{sent}, p) & \iff \{g_p : g \in G_{sent} \} = \{0, 1\} \\
        \end{array}\right\} \\
  Irrel?(G_{sent}, p) &= \left\{\begin{array}{lr}
        Ambig                        & \iff \exists g \in G_{sent} :
                                       (pair_p^g \notin \bar{S}_{sent}^g) \cap (pair_p^g \in G) \\
        Irrel                        & \iff  otherwise \\
        \end{array}\right\} \\
  \end{align*}
* Learning $g$ or any Superset
  [[./images/all-triggers-supersets.png]]

  - Here's how many relevant sentences we "gain" by doing that:

  | opt    | 	ns     | 	nt     | 	whm    | 	VtoI   | 	ItoC | 	ah     | QInv          |
  | 29,195 | 	33,629 | 	29,429 | 	18,421 | 	22,647 | 	71   | 	22,647 | 	5,732 |
* Learning $g$ or any Superset
  - Here's how Colag English looks under that definition:

  [[./images/english-triggers-supersets.png]]
# * Augmenting the VL
#   #+ATTR_LATEX: :align |r|l|l|
#   |-------------+------+----------------------------------------|
#   |             | cnvg | learns                                 |
#   |-------------+------+----------------------------------------|
#   | ROVL        |  80% | 35, 611 + supers (547, 99[eqviv], 553) |
#   |-------------+------+----------------------------------------|
#   | RORVL       |   0% | 611 + supers (803, 547, 867)           |
#   |-------------+------+----------------------------------------|
#   | RORVL+EQUIV |   0% | 809, 873, 617 (<- not supers), 553     |
#   |-------------+------+----------------------------------------|
#   | RORVL+SUPER |  65% | 99, 547, 611, 35, 617[not super]       |
#   |-------------+------+----------------------------------------|

#   #+ATTR_LATEX: :align |r|l|l|l|
#   |-------------+-----------+-----------+--------------|
#   |             | ns?       | nt?       | VotI?        |
#   |-------------+-----------+-----------+--------------|
#   | ROVL        | sometimes | sometimes | yes          |
#   |-------------+-----------+-----------+--------------|
#   | RORVL       | never     | never     | yes          |
#   |-------------+-----------+-----------+--------------|
#   | RORVL+EQUIV | never     | never     | always wrong |
#   |-------------+-----------+-----------+--------------|
#   | RORVL+SUPER | sometimes | sometimes | sometimes    |
#   |-------------+-----------+-----------+--------------|

# * Supersets of 611
#   :PROPERTIES:
#   :BEAMER_opt: shrink=12
#   :END:
#   - 99 is weakly equivalent.
#   #+ATTR_LATEX: :align |r|l|l|l|l|l|l|l|l|l|l|l|l|l|
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | $g$ | sp | hip | hcp | opt | ns | nt | whm | pi | tm | VtoI | ItoC | ah | QInv |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | 611 |  0 |   0 |   0 |   1 |  0 |  0 |   1 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | 547 |  0 |   0 |   0 |   1 |  0 |  0 |   0 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# |  35 |  0 |   0 |   0 |   0 |  0 |  0 |   0 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | 163 |  0 |   0 |   0 |   0 |  0 |  1 |   0 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | 803 |  0 |   0 |   0 |   1 |  1 |  0 |   0 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# |  99 |  0 |   0 |   0 |   0 |  0 |  0 |   1 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | 867 |  0 |   0 |   0 |   1 |  1 |  0 |   1 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
# | 227 |  0 |   0 |   0 |   0 |  0 |  1 |   1 |  1 |  0 |    0 |    0 |  1 |    1 |
# |-----+----+-----+-----+-----+----+----+-----+----+----+------+------+----+------|
